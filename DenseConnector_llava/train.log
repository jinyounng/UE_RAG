/data3/jykim/anaconda3/envs/llava/lib/python3.10/site-packages/torch/cuda/__init__.py:51: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
[2025-10-07 05:43:05,803] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-07 05:43:06,740] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3: setting --include=localhost:0,1,2,3
[2025-10-07 05:43:06,740] [INFO] [runner.py:571:main] cmd = /data3/jykim/anaconda3/envs/llava/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None dc/train/train_mem.py --deepspeed ./scripts/zero2.json --model_name_or_path ./ckpt/vicuna-7b-v1.5 --version plain --data_path /data3/DB/dataset/LLaVA-Pretrain/blip_laion_cc_sbu_558k.json --image_folder /data3/DB/dataset/LLaVA-Pretrain --vision_tower openai/clip-vit-large-patch14-336 --mm_projector_type mlp2x_gelu --mm_dense_connector_type dci --tune_mm_mlp_adapter True --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --bf16 True --output_dir ./checkpoints_stage1/DenseConnector-v1.5-7b-Pretrain --num_train_epochs 1 --per_device_train_batch_size 16 --per_device_eval_batch_size 4 --gradient_accumulation_steps 4 --evaluation_strategy no --save_strategy steps --save_steps 500 --save_total_limit 1 --learning_rate 1e-3 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb
/data3/jykim/anaconda3/envs/llava/lib/python3.10/site-packages/torch/cuda/__init__.py:51: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
[2025-10-07 05:43:08,408] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-07 05:43:09,187] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2025-10-07 05:43:09,187] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0
[2025-10-07 05:43:09,187] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2025-10-07 05:43:09,187] [INFO] [launch.py:163:main] dist_world_size=4
[2025-10-07 05:43:09,187] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
Traceback (most recent call last):
  File "/data3/jykim/Projects/VLM/DenseConnector_llava/dc/train/train_mem.py", line 11, in <module>
    from dc.train.train import train
ModuleNotFoundError: No module named 'dc'
Traceback (most recent call last):
  File "/data3/jykim/Projects/VLM/DenseConnector_llava/dc/train/train_mem.py", line 11, in <module>
    from dc.train.train import train
ModuleNotFoundError: No module named 'dc'
Traceback (most recent call last):
  File "/data3/jykim/Projects/VLM/DenseConnector_llava/dc/train/train_mem.py", line 11, in <module>
    from dc.train.train import train
ModuleNotFoundError: No module named 'dc'
Traceback (most recent call last):
  File "/data3/jykim/Projects/VLM/DenseConnector_llava/dc/train/train_mem.py", line 11, in <module>
    from dc.train.train import train
ModuleNotFoundError: No module named 'dc'
[2025-10-07 05:43:10,192] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 3051803
[2025-10-07 05:43:10,204] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 3051804
[2025-10-07 05:43:10,205] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 3051805
[2025-10-07 05:43:10,213] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 3051806
[2025-10-07 05:43:10,221] [ERROR] [launch.py:321:sigkill_handler] ['/data3/jykim/anaconda3/envs/llava/bin/python3.10', '-u', 'dc/train/train_mem.py', '--local_rank=3', '--deepspeed', './scripts/zero2.json', '--model_name_or_path', './ckpt/vicuna-7b-v1.5', '--version', 'plain', '--data_path', '/data3/DB/dataset/LLaVA-Pretrain/blip_laion_cc_sbu_558k.json', '--image_folder', '/data3/DB/dataset/LLaVA-Pretrain', '--vision_tower', 'openai/clip-vit-large-patch14-336', '--mm_projector_type', 'mlp2x_gelu', '--mm_dense_connector_type', 'dci', '--tune_mm_mlp_adapter', 'True', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--bf16', 'True', '--output_dir', './checkpoints_stage1/DenseConnector-v1.5-7b-Pretrain', '--num_train_epochs', '1', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '4', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '1e-3', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'wandb'] exits with return code = 1
